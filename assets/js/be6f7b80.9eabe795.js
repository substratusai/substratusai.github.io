"use strict";(self.webpackChunksubstratus_website=self.webpackChunksubstratus_website||[]).push([[895],{3905:(e,t,a)=>{a.d(t,{Zo:()=>c,kt:()=>b});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function l(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?l(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},l=Object.keys(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var u=n.createContext({}),i=function(e){var t=n.useContext(u),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},c=function(e){var t=i(e.components);return n.createElement(u.Provider,{value:t},e.children)},p="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,l=e.originalType,u=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),p=i(a),m=r,b=p["".concat(u,".").concat(m)]||p[m]||d[m]||l;return a?n.createElement(b,o(o({ref:t},c),{},{components:a})):n.createElement(b,o({ref:t},c))}));function b(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var l=a.length,o=new Array(l);o[0]=m;var s={};for(var u in t)hasOwnProperty.call(t,u)&&(s[u]=t[u]);s.originalType=e,s[p]="string"==typeof e?e:r,o[1]=s;for(var i=2;i<l;i++)o[i]=a[i];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}m.displayName="MDXCreateElement"},6102:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>S,contentTitle:()=>x,default:()=>V,frontMatter:()=>P,metadata:()=>O,toc:()=>q});var n=a(7462),r=a(7294),l=a(3905),o=a(6010),s=a(2466),u=a(6550),i=a(1980),c=a(7392),p=a(12);function d(e){return function(e){return r.Children.map(e,(e=>{if(!e||(0,r.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}(e).map((e=>{let{props:{value:t,label:a,attributes:n,default:r}}=e;return{value:t,label:a,attributes:n,default:r}}))}function m(e){const{values:t,children:a}=e;return(0,r.useMemo)((()=>{const e=t??d(a);return function(e){const t=(0,c.l)(e,((e,t)=>e.value===t.value));if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[t,a])}function b(e){let{value:t,tabValues:a}=e;return a.some((e=>e.value===t))}function k(e){let{queryString:t=!1,groupId:a}=e;const n=(0,u.k6)(),l=function(e){let{queryString:t=!1,groupId:a}=e;if("string"==typeof t)return t;if(!1===t)return null;if(!0===t&&!a)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return a??null}({queryString:t,groupId:a});return[(0,i._X)(l),(0,r.useCallback)((e=>{if(!l)return;const t=new URLSearchParams(n.location.search);t.set(l,e),n.replace({...n.location,search:t.toString()})}),[l,n])]}function h(e){const{defaultValue:t,queryString:a=!1,groupId:n}=e,l=m(e),[o,s]=(0,r.useState)((()=>function(e){let{defaultValue:t,tabValues:a}=e;if(0===a.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!b({value:t,tabValues:a}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${t}" but none of its children has the corresponding value. Available values are: ${a.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return t}const n=a.find((e=>e.default))??a[0];if(!n)throw new Error("Unexpected error: 0 tabValues");return n.value}({defaultValue:t,tabValues:l}))),[u,i]=k({queryString:a,groupId:n}),[c,d]=function(e){let{groupId:t}=e;const a=function(e){return e?`docusaurus.tab.${e}`:null}(t),[n,l]=(0,p.Nk)(a);return[n,(0,r.useCallback)((e=>{a&&l.set(e)}),[a,l])]}({groupId:n}),h=(()=>{const e=u??c;return b({value:e,tabValues:l})?e:null})();(0,r.useLayoutEffect)((()=>{h&&s(h)}),[h]);return{selectedValue:o,selectValue:(0,r.useCallback)((e=>{if(!b({value:e,tabValues:l}))throw new Error(`Can't select invalid tab value=${e}`);s(e),i(e),d(e)}),[i,d,l]),tabValues:l}}var f=a(2389);const g={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};function v(e){let{className:t,block:a,selectedValue:l,selectValue:u,tabValues:i}=e;const c=[],{blockElementScrollPositionUntilNextRender:p}=(0,s.o5)(),d=e=>{const t=e.currentTarget,a=c.indexOf(t),n=i[a].value;n!==l&&(p(t),u(n))},m=e=>{let t=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{const a=c.indexOf(e.currentTarget)+1;t=c[a]??c[0];break}case"ArrowLeft":{const a=c.indexOf(e.currentTarget)-1;t=c[a]??c[c.length-1];break}}t?.focus()};return r.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,o.Z)("tabs",{"tabs--block":a},t)},i.map((e=>{let{value:t,label:a,attributes:s}=e;return r.createElement("li",(0,n.Z)({role:"tab",tabIndex:l===t?0:-1,"aria-selected":l===t,key:t,ref:e=>c.push(e),onKeyDown:m,onClick:d},s,{className:(0,o.Z)("tabs__item",g.tabItem,s?.className,{"tabs__item--active":l===t})}),a??t)})))}function y(e){let{lazy:t,children:a,selectedValue:n}=e;const l=(Array.isArray(a)?a:[a]).filter(Boolean);if(t){const e=l.find((e=>e.props.value===n));return e?(0,r.cloneElement)(e,{className:"margin-top--md"}):null}return r.createElement("div",{className:"margin-top--md"},l.map(((e,t)=>(0,r.cloneElement)(e,{key:t,hidden:e.props.value!==n}))))}function w(e){const t=h(e);return r.createElement("div",{className:(0,o.Z)("tabs-container",g.tabList)},r.createElement(v,(0,n.Z)({},e,t)),r.createElement(y,(0,n.Z)({},e,t)))}function N(e){const t=(0,f.Z)();return r.createElement(w,(0,n.Z)({key:String(t)},e))}const T={tabItem:"tabItem_Ymn6"};function I(e){let{children:t,hidden:a,className:n}=e;return r.createElement("div",{role:"tabpanel",className:(0,o.Z)(T.tabItem,n),hidden:a},t)}const P={sidebar_position:1},x="Local - Kind",O={unversionedId:"quickstart/local-kind",id:"quickstart/local-kind",title:"Local - Kind",description:"In this quickstart guide, you will install Substratus into a Kubernetes cluster running on your local machine and deploy an Open Source LLM.",source:"@site/docs/quickstart/local-kind.md",sourceDirName:"quickstart",slug:"/quickstart/local-kind",permalink:"/docs/quickstart/local-kind",draft:!1,editUrl:"https://github.com/substratusai/substratusai.github.io/tree/main/docs/quickstart/local-kind.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"Quickstart",permalink:"/docs/category/quickstart"},next:{title:"GCP - Google Cloud",permalink:"/docs/quickstart/gcp"}},S={},q=[{value:"Required Tools",id:"required-tools",level:2},{value:"Setup",id:"setup",level:2},{value:"Deploy LLM",id:"deploy-llm",level:2},{value:"Talk to your LLM!",id:"talk-to-your-llm",level:2},{value:"Cleanup",id:"cleanup",level:2}],E={toc:q},C="wrapper";function V(e){let{components:t,...a}=e;return(0,l.kt)(C,(0,n.Z)({},E,a,{components:t,mdxType:"MDXLayout"}),(0,l.kt)("h1",{id:"local---kind"},"Local - Kind"),(0,l.kt)("p",null,"In this quickstart guide, you will install Substratus into a Kubernetes cluster running on your local machine and deploy an Open Source LLM."),(0,l.kt)("h2",{id:"required-tools"},"Required Tools"),(0,l.kt)("p",null,"Make sure you have the following tools installed and up to date."),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"https://kind.sigs.k8s.io/docs/user/quick-start/#installation"},"kind")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"https://kubernetes.io/docs/tasks/tools/#kubectl"},"kubectl"))),(0,l.kt)("h2",{id:"setup"},"Setup"),(0,l.kt)("p",null,"Larger models require a GPU and Kind can work with GPUs.\nIt's recommended to choose GPU if you have a GPU available on your machine."),(0,l.kt)(N,{groupId:"kind-mode",queryString:!0,mdxType:"Tabs"},(0,l.kt)(I,{value:"cpu",label:"CPU",default:!0,mdxType:"TabItem"},(0,l.kt)("p",null,"Create a local Kubernetes cluster using Kind."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"kind create cluster --name substratus --config - <<EOF\napiVersion: kind.x-k8s.io/v1alpha4\nkind: Cluster\nnodes:\n- role: control-plane\n  extraPortMappings:\n  - containerPort: 30080\n    hostPort: 30080\nEOF\n"))),(0,l.kt)(I,{value:"gpu",label:"GPU",mdxType:"TabItem"},(0,l.kt)("p",null,"Install the NVIDIA container toolkit for Docker: ",(0,l.kt)("a",{parentName:"p",href:"https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html"},"Install Guide")),(0,l.kt)("p",null,"The steps below are all required as part of a workaround for Kind to\nsupport GPUs. You can read more about the workaround on the ",(0,l.kt)("a",{parentName:"p",href:"https://github.com/kubernetes-sigs/kind/pull/3257#issuecomment-1607287275"},"Kind PR\nfor GPU support")),(0,l.kt)("p",null,"Configure nvidia as the default runtime for Docker:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"sudo nvidia-ctk runtime configure --runtime=docker --set-as-default\n")),(0,l.kt)("p",null,"Restart docker daemon:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"sudo systemctl restart docker\n")),(0,l.kt)("p",null,"Change ",(0,l.kt)("inlineCode",{parentName:"p"},"accept-nvidia-visible-devices-as-volume-mounts")," to ",(0,l.kt)("inlineCode",{parentName:"p"},"true")," in ",(0,l.kt)("inlineCode",{parentName:"p"},"/etc/nvidia-container-runtime/config.toml"),":"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"sudo sed -i '/accept-nvidia-visible-devices-as-volume-mounts/c\\accept-nvidia-visible-devices-as-volume-mounts = true' \\\n  /etc/nvidia-container-runtime/config.toml\n")),(0,l.kt)("p",null,"Create the kind cluster:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"kind create cluster --name substratus --config - <<EOF\napiVersion: kind.x-k8s.io/v1alpha4\nkind: Cluster\nnodes:\n- role: control-plane\n  image: kindest/node:v1.27.3@sha256:3966ac761ae0136263ffdb6cfd4db23ef8a83cba8a463690e98317add2c9ba72\n  extraPortMappings:\n  - containerPort: 30080\n    hostPort: 30080\n  # required for GPU workaround\n  extraMounts:\n    - hostPath: /dev/null\n      containerPath: /var/run/nvidia-container-devices/all\nEOF\n")),(0,l.kt)("p",null,"Create required symlink inside kind container (",(0,l.kt)("a",{parentName:"p",href:"https://github.com/NVIDIA/nvidia-docker/issues/614#issuecomment-423991632"},"workaround")," for issue with nvidia operator):"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"docker exec -ti substratus-control-plane ln -s /sbin/ldconfig /sbin/ldconfig.real\n")),(0,l.kt)("p",null,"Install the NVIDIA GPU operator:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"helm repo add nvidia https://helm.ngc.nvidia.com/nvidia || true\nhelm repo update\nhelm install --wait --generate-name \\\n     -n gpu-operator --create-namespace \\\n     nvidia/gpu-operator --set driver.enabled=false\n")))),(0,l.kt)("p",null,"Install Substratus."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl apply -f https://raw.githubusercontent.com/substratusai/substratus/main/install/kind/manifests.yaml\n")),(0,l.kt)("h2",{id:"deploy-llm"},"Deploy LLM"),(0,l.kt)("p",null,"Now that Substratus is running let's deploy an Open Source LLM."),(0,l.kt)(N,{groupId:"kind-mode",queryString:!0,mdxType:"Tabs"},(0,l.kt)(I,{value:"cpu",label:"CPU",default:!0,mdxType:"TabItem"},(0,l.kt)("p",null,"Running CPU mode only supports smaller models. Rou can use the (relatively-tiny) Facebook OPT 125M model (125 million parameters) from HuggingFace."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: substratus.ai/v1\nkind: Model\nmetadata:\n  namespace: default\n  name: facebook-opt-125m\nspec:\n  image: substratusai/model-loader-huggingface\n  params:\n    name: facebook/opt-125m\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl apply -f https://raw.githubusercontent.com/substratusai/substratus/main/examples/facebook-opt-125m/base-model.yaml\n")),(0,l.kt)("p",null,"The model is now being downloaded from HuggingFace into local storage.\nYou can apply the following Server manifest to deploy the Model once it is imported."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: substratus.ai/v1\nkind: Server\nmetadata:\n  name: facebook-opt-125m\nspec:\n  image: substratusai/model-server-basaran\n  model:\n    name: facebook-opt-125m\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl apply -f https://raw.githubusercontent.com/substratusai/substratus/main/examples/facebook-opt-125m/base-server.yaml\n"))),(0,l.kt)(I,{value:"gpu",label:"GPU",mdxType:"TabItem"},(0,l.kt)("p",null,"Running Kind with GPU allows you to use bigger models such as the Falcon 7B model, which\nhas 7 billion parameters. The falcon-7b-instruct model requires about 3.5 GB of\nGPU memory when serving in 4 bit mode."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: substratus.ai/v1\nkind: Model\nmetadata:\n  name: falcon-7b-instruct\nspec:\n  image: substratusai/model-loader-huggingface\n  params:\n    name: tiiuae/falcon-7b-instruct\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl apply -f https://raw.githubusercontent.com/substratusai/substratus/main/examples/falcon-7b-instruct/base-model.yaml\n")),(0,l.kt)("p",null,"The model is now being downloaded from HuggingFace into local storage.\nYou can apply the following Server manifest to deploy the Model once it is imported."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: substratus.ai/v1\nkind: Server\nmetadata:\n  name: falcon-7b-instruct\nspec:\n  image: substratusai/model-server-basaran\n  model:\n    name: falcon-7b-instruct\n  params:\n    load_in_4bit: "true"\n  resources:\n    gpu:\n      count: 1\n')),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl apply -f https://raw.githubusercontent.com/substratusai/substratus/main/examples/falcon-7b-instruct/server-4bit-any-gpu.yaml\n")))),(0,l.kt)("p",null,"You can check on the progress of both processes using the following command."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl get ai\n")),(0,l.kt)("p",null,"When the Server reports a ",(0,l.kt)("inlineCode",{parentName:"p"},"Ready")," status, proceed to the next section to test it out."),(0,l.kt)("h2",{id:"talk-to-your-llm"},"Talk to your LLM!"),(0,l.kt)(N,{groupId:"kind-mode",queryString:!0,mdxType:"Tabs"},(0,l.kt)(I,{value:"cpu",label:"CPU",default:!0,mdxType:"TabItem"},(0,l.kt)("admonition",{type:"note"},(0,l.kt)("p",{parentName:"admonition"},"The 125 million parameters used in the CPU example is not much in the world of LLMs. Expect some whacky answers to your prompts!")),(0,l.kt)("p",null,"In order to access the model for exploratory purposes, forward ports from within the cluster to your local machine."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl port-forward service/facebook-opt-125m-server 8080:8080\n"))),(0,l.kt)(I,{value:"gpu",label:"GPU",mdxType:"TabItem"},(0,l.kt)("p",null,"In order to access the model for exploratory purposes, forward ports from within the cluster to your local machine."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl port-forward service/falcon-7b-instruct-server 8080:8080\n")))),(0,l.kt)("p",null,"All substratus Servers ship with an API and interactive frontend. Open up your browser to ",(0,l.kt)("a",{parentName:"p",href:"http://localhost:8080/"},"http://localhost:8080/")," and talk to your model! Alternatively, request text generation via the OpenAI compatible HTTP API:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},'curl http://localhost:8080/v1/completions \\\n  -H "Content-Type: application/json" \\\n  -d \'{ \\\n    "model": "facebook-opt-125m", \\\n    "prompt": "Who was the first president of the United States? ", \\\n    "max_tokens": 10\\\n  }\'\n')),(0,l.kt)("p",null,"The process that is serving the model can be stopped by simply deleting the same Server object that was applied before."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl delete server facebook-opt-125m\n")),(0,l.kt)("h2",{id:"cleanup"},"Cleanup"),(0,l.kt)("p",null,"Delete the local cluster."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"kind delete cluster --name substratus\n")),(0,l.kt)("p",null,"If you are interested in continuing your journey through Substratus, take a look at the ",(0,l.kt)("a",{parentName:"p",href:"../category/guides"},"guides")," to learn how to finetune models with your own dataset and much more!"),(0,l.kt)("p",null,"To learn more about how Substratus works, check out the ",(0,l.kt)("a",{parentName:"p",href:"/docs/overview"},"Overview")," page."))}V.isMDXComponent=!0}}]);