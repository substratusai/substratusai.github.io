"use strict";(self.webpackChunksubstratus_website=self.webpackChunksubstratus_website||[]).push([[3398],{4226:(s,e,a)=>{a.r(e),a.d(e,{assets:()=>i,contentTitle:()=>t,default:()=>o,frontMatter:()=>r,metadata:()=>m,toc:()=>c});var n=a(5893),l=a(1151);const r={slug:"calculating-gpu-memory-for-llm",title:"Calculating GPU memory for serving LLMs",authors:[{name:"Sam Stoelinga",title:"Engineer",url:"https://github.com/samos123"}],tags:["llm","gpu","memory"],image:"/img/llm-gpu-mem-formula.png"},t=void 0,m={permalink:"/blog/calculating-gpu-memory-for-llm",editUrl:"https://github.com/substratusai/substratusai.github.io/tree/main/blog/2023-11-16-calculating-gpu-memory-for-llm.md",source:"@site/blog/2023-11-16-calculating-gpu-memory-for-llm.md",title:"Calculating GPU memory for serving LLMs",description:"How many GPUs do I need to be able to serve Llama 70B? In order",date:"2023-11-16T00:00:00.000Z",formattedDate:"November 16, 2023",tags:[{label:"llm",permalink:"/blog/tags/llm"},{label:"gpu",permalink:"/blog/tags/gpu"},{label:"memory",permalink:"/blog/tags/memory"}],readingTime:2.115,hasTruncateMarker:!1,authors:[{name:"Sam Stoelinga",title:"Engineer",url:"https://github.com/samos123"}],frontMatter:{slug:"calculating-gpu-memory-for-llm",title:"Calculating GPU memory for serving LLMs",authors:[{name:"Sam Stoelinga",title:"Engineer",url:"https://github.com/samos123"}],tags:["llm","gpu","memory"],image:"/img/llm-gpu-mem-formula.png"},unlisted:!1,nextItem:{title:"Deploying Mistral 7B Instruct on K8s using TGI",permalink:"/blog/mistral-7b-instruct-k8s-helm-tgi"}},i={authorsImageUrls:[void 0]},c=[{value:"GPU memory required for serving Llama 70B",id:"gpu-memory-required-for-serving-llama-70b",level:3},{value:"Relevant tools and resources",id:"relevant-tools-and-resources",level:3}];function h(s){const e={a:"a",annotation:"annotation",h3:"h3",li:"li",math:"math",mfrac:"mfrac",mi:"mi",mn:"mn",mo:"mo",mrow:"mrow",ol:"ol",p:"p",semantics:"semantics",span:"span",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,l.a)(),...s.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.p,{children:"How many GPUs do I need to be able to serve Llama 70B? In order\nto answer that, you need to know how much GPU memory will be required by\nthe Large Language Model."}),"\n",(0,n.jsx)(e.p,{children:"The formula is simple:"}),"\n",(0,n.jsx)(e.span,{className:"katex-display",children:(0,n.jsxs)(e.span,{className:"katex",children:[(0,n.jsx)(e.span,{className:"katex-mathml",children:(0,n.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block",children:(0,n.jsxs)(e.semantics,{children:[(0,n.jsxs)(e.mrow,{children:[(0,n.jsx)(e.mi,{children:"M"}),(0,n.jsx)(e.mo,{children:"="}),(0,n.jsxs)(e.mfrac,{children:[(0,n.jsxs)(e.mrow,{children:[(0,n.jsx)(e.mo,{stretchy:"false",children:"("}),(0,n.jsx)(e.mi,{children:"P"}),(0,n.jsx)(e.mo,{children:"\u2217"}),(0,n.jsx)(e.mn,{children:"4"}),(0,n.jsx)(e.mi,{children:"B"}),(0,n.jsx)(e.mo,{stretchy:"false",children:")"})]}),(0,n.jsxs)(e.mrow,{children:[(0,n.jsx)(e.mo,{stretchy:"false",children:"("}),(0,n.jsx)(e.mn,{children:"32"}),(0,n.jsx)(e.mi,{mathvariant:"normal",children:"/"}),(0,n.jsx)(e.mi,{children:"Q"}),(0,n.jsx)(e.mo,{stretchy:"false",children:")"})]})]}),(0,n.jsx)(e.mo,{children:"\u2217"}),(0,n.jsx)(e.mn,{children:"1.2"})]}),(0,n.jsx)(e.annotation,{encoding:"application/x-tex",children:"M = \\dfrac{(P * 4B)}{ (32  / Q)} * 1.2"})]})})}),(0,n.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,n.jsxs)(e.span,{className:"base",children:[(0,n.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,n.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.10903em"},children:"M"}),(0,n.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,n.jsx)(e.span,{className:"mrel",children:"="}),(0,n.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,n.jsxs)(e.span,{className:"base",children:[(0,n.jsx)(e.span,{className:"strut",style:{height:"2.363em",verticalAlign:"-0.936em"}}),(0,n.jsxs)(e.span,{className:"mord",children:[(0,n.jsx)(e.span,{className:"mopen nulldelimiter"}),(0,n.jsx)(e.span,{className:"mfrac",children:(0,n.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,n.jsxs)(e.span,{className:"vlist-r",children:[(0,n.jsxs)(e.span,{className:"vlist",style:{height:"1.427em"},children:[(0,n.jsxs)(e.span,{style:{top:"-2.314em"},children:[(0,n.jsx)(e.span,{className:"pstrut",style:{height:"3em"}}),(0,n.jsxs)(e.span,{className:"mord",children:[(0,n.jsx)(e.span,{className:"mopen",children:"("}),(0,n.jsx)(e.span,{className:"mord",children:"32/"}),(0,n.jsx)(e.span,{className:"mord mathnormal",children:"Q"}),(0,n.jsx)(e.span,{className:"mclose",children:")"})]})]}),(0,n.jsxs)(e.span,{style:{top:"-3.23em"},children:[(0,n.jsx)(e.span,{className:"pstrut",style:{height:"3em"}}),(0,n.jsx)(e.span,{className:"frac-line",style:{borderBottomWidth:"0.04em"}})]}),(0,n.jsxs)(e.span,{style:{top:"-3.677em"},children:[(0,n.jsx)(e.span,{className:"pstrut",style:{height:"3em"}}),(0,n.jsxs)(e.span,{className:"mord",children:[(0,n.jsx)(e.span,{className:"mopen",children:"("}),(0,n.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.13889em"},children:"P"}),(0,n.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,n.jsx)(e.span,{className:"mbin",children:"\u2217"}),(0,n.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,n.jsx)(e.span,{className:"mord",children:"4"}),(0,n.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.05017em"},children:"B"}),(0,n.jsx)(e.span,{className:"mclose",children:")"})]})]})]}),(0,n.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,n.jsx)(e.span,{className:"vlist-r",children:(0,n.jsx)(e.span,{className:"vlist",style:{height:"0.936em"},children:(0,n.jsx)(e.span,{})})})]})}),(0,n.jsx)(e.span,{className:"mclose nulldelimiter"})]}),(0,n.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,n.jsx)(e.span,{className:"mbin",children:"\u2217"}),(0,n.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,n.jsxs)(e.span,{className:"base",children:[(0,n.jsx)(e.span,{className:"strut",style:{height:"0.6444em"}}),(0,n.jsx)(e.span,{className:"mord",children:"1.2"})]})]})]})}),"\n",(0,n.jsxs)(e.table,{children:[(0,n.jsx)(e.thead,{children:(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.th,{children:"Symbol"}),(0,n.jsx)(e.th,{children:"Description"})]})}),(0,n.jsxs)(e.tbody,{children:[(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:"M"}),(0,n.jsx)(e.td,{children:"GPU memory expressed in Gigabyte"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:"P"}),(0,n.jsx)(e.td,{children:"The amount of parameters in the model. E.g. a 7B model has 7 billion parameters."})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:"4B"}),(0,n.jsx)(e.td,{children:"4 bytes, expressing the bytes used for each parameter"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:"32"}),(0,n.jsx)(e.td,{children:"There are 32 bits in 4 bytes"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:"Q"}),(0,n.jsx)(e.td,{children:"The amount of bits that should be used for loading the model. E.g. 16 bits, 8 bits or 4 bits."})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:"1.2"}),(0,n.jsx)(e.td,{children:"Represents a 20% overhead of loading additional things in GPU memory."})]})]})]}),"\n",(0,n.jsx)(e.p,{children:"Now let's try out some examples."}),"\n",(0,n.jsx)(e.h3,{id:"gpu-memory-required-for-serving-llama-70b",children:"GPU memory required for serving Llama 70B"}),"\n",(0,n.jsx)(e.p,{children:"Let's try it out for Llama 70B that we will load in 16 bit.\nThe model has 70 billion parameters."}),"\n",(0,n.jsx)(e.span,{className:"katex-display",children:(0,n.jsxs)(e.span,{className:"katex",children:[(0,n.jsx)(e.span,{className:"katex-mathml",children:(0,n.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block",children:(0,n.jsxs)(e.semantics,{children:[(0,n.jsxs)(e.mrow,{children:[(0,n.jsxs)(e.mfrac,{children:[(0,n.jsxs)(e.mrow,{children:[(0,n.jsx)(e.mn,{children:"70"}),(0,n.jsx)(e.mo,{children:"\u2217"}),(0,n.jsx)(e.mn,{children:"4"}),(0,n.jsxs)(e.mrow,{children:[(0,n.jsx)(e.mi,{mathvariant:"normal",children:"b"}),(0,n.jsx)(e.mi,{mathvariant:"normal",children:"y"}),(0,n.jsx)(e.mi,{mathvariant:"normal",children:"t"}),(0,n.jsx)(e.mi,{mathvariant:"normal",children:"e"}),(0,n.jsx)(e.mi,{mathvariant:"normal",children:"s"})]})]}),(0,n.jsxs)(e.mrow,{children:[(0,n.jsx)(e.mn,{children:"32"}),(0,n.jsx)(e.mi,{mathvariant:"normal",children:"/"}),(0,n.jsx)(e.mn,{children:"16"})]})]}),(0,n.jsx)(e.mo,{children:"\u2217"}),(0,n.jsx)(e.mn,{children:"1.2"}),(0,n.jsx)(e.mo,{children:"="}),(0,n.jsx)(e.mn,{children:"168"}),(0,n.jsxs)(e.mrow,{children:[(0,n.jsx)(e.mi,{mathvariant:"normal",children:"G"}),(0,n.jsx)(e.mi,{mathvariant:"normal",children:"B"})]})]}),(0,n.jsx)(e.annotation,{encoding:"application/x-tex",children:"\\dfrac{70  * 4 \\mathrm{bytes}}{32 / 16} * 1.2 = 168\\mathrm{GB}"})]})})}),(0,n.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,n.jsxs)(e.span,{className:"base",children:[(0,n.jsx)(e.span,{className:"strut",style:{height:"2.3074em",verticalAlign:"-0.936em"}}),(0,n.jsxs)(e.span,{className:"mord",children:[(0,n.jsx)(e.span,{className:"mopen nulldelimiter"}),(0,n.jsx)(e.span,{className:"mfrac",children:(0,n.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,n.jsxs)(e.span,{className:"vlist-r",children:[(0,n.jsxs)(e.span,{className:"vlist",style:{height:"1.3714em"},children:[(0,n.jsxs)(e.span,{style:{top:"-2.314em"},children:[(0,n.jsx)(e.span,{className:"pstrut",style:{height:"3em"}}),(0,n.jsx)(e.span,{className:"mord",children:(0,n.jsx)(e.span,{className:"mord",children:"32/16"})})]}),(0,n.jsxs)(e.span,{style:{top:"-3.23em"},children:[(0,n.jsx)(e.span,{className:"pstrut",style:{height:"3em"}}),(0,n.jsx)(e.span,{className:"frac-line",style:{borderBottomWidth:"0.04em"}})]}),(0,n.jsxs)(e.span,{style:{top:"-3.677em"},children:[(0,n.jsx)(e.span,{className:"pstrut",style:{height:"3em"}}),(0,n.jsxs)(e.span,{className:"mord",children:[(0,n.jsx)(e.span,{className:"mord",children:"70"}),(0,n.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,n.jsx)(e.span,{className:"mbin",children:"\u2217"}),(0,n.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,n.jsx)(e.span,{className:"mord",children:"4"}),(0,n.jsx)(e.span,{className:"mord",children:(0,n.jsx)(e.span,{className:"mord mathrm",children:"bytes"})})]})]})]}),(0,n.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,n.jsx)(e.span,{className:"vlist-r",children:(0,n.jsx)(e.span,{className:"vlist",style:{height:"0.936em"},children:(0,n.jsx)(e.span,{})})})]})}),(0,n.jsx)(e.span,{className:"mclose nulldelimiter"})]}),(0,n.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,n.jsx)(e.span,{className:"mbin",children:"\u2217"}),(0,n.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,n.jsxs)(e.span,{className:"base",children:[(0,n.jsx)(e.span,{className:"strut",style:{height:"0.6444em"}}),(0,n.jsx)(e.span,{className:"mord",children:"1.2"}),(0,n.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,n.jsx)(e.span,{className:"mrel",children:"="}),(0,n.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,n.jsxs)(e.span,{className:"base",children:[(0,n.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,n.jsx)(e.span,{className:"mord",children:"168"}),(0,n.jsx)(e.span,{className:"mord",children:(0,n.jsx)(e.span,{className:"mord mathrm",children:"GB"})})]})]})]})}),"\n",(0,n.jsx)(e.p,{children:"That's quite a lot of memory. A single A100 80GB wouldn't be enough, although\n2x A100 80GB should be enough to serve the Llama 2 70B model in 16 bit mode."}),"\n",(0,n.jsx)(e.p,{children:(0,n.jsx)(e.strong,{children:"How to further reduce GPU memory required for Llama 2 70B?"})}),"\n",(0,n.jsx)(e.p,{children:"Quantization is a method to reduce the memory footprint. Quantization is able to do this by reducing the precision of the model's parameters from floating-point to lower-bit representations, such as 8-bit integers. This process significantly decreases the memory and computational requirements, enabling more efficient deployment of the model, particularly on devices with limited resources. However, it requires careful management to maintain the model's performance, as reducing precision can potentially impact the accuracy of the outputs."}),"\n",(0,n.jsx)(e.p,{children:"In general, the consensus seems to be that 8 bit quantization achieves similar performance to using 16 bit. However, 4 bit quantization could have a noticeable impact to the model performance."}),"\n",(0,n.jsxs)(e.p,{children:["Let's do another example where we use ",(0,n.jsx)(e.strong,{children:"4 bit quantization of Llama 2 70B"}),":"]}),"\n",(0,n.jsx)(e.span,{className:"katex-display",children:(0,n.jsxs)(e.span,{className:"katex",children:[(0,n.jsx)(e.span,{className:"katex-mathml",children:(0,n.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block",children:(0,n.jsxs)(e.semantics,{children:[(0,n.jsxs)(e.mrow,{children:[(0,n.jsxs)(e.mfrac,{children:[(0,n.jsxs)(e.mrow,{children:[(0,n.jsx)(e.mn,{children:"70"}),(0,n.jsx)(e.mo,{children:"\u2217"}),(0,n.jsx)(e.mn,{children:"4"}),(0,n.jsxs)(e.mrow,{children:[(0,n.jsx)(e.mi,{mathvariant:"normal",children:"b"}),(0,n.jsx)(e.mi,{mathvariant:"normal",children:"y"}),(0,n.jsx)(e.mi,{mathvariant:"normal",children:"t"}),(0,n.jsx)(e.mi,{mathvariant:"normal",children:"e"}),(0,n.jsx)(e.mi,{mathvariant:"normal",children:"s"})]})]}),(0,n.jsxs)(e.mrow,{children:[(0,n.jsx)(e.mn,{children:"32"}),(0,n.jsx)(e.mi,{mathvariant:"normal",children:"/"}),(0,n.jsx)(e.mn,{children:"4"})]})]}),(0,n.jsx)(e.mo,{children:"\u2217"}),(0,n.jsx)(e.mn,{children:"1.2"}),(0,n.jsx)(e.mo,{children:"="}),(0,n.jsx)(e.mn,{children:"42"}),(0,n.jsxs)(e.mrow,{children:[(0,n.jsx)(e.mi,{mathvariant:"normal",children:"G"}),(0,n.jsx)(e.mi,{mathvariant:"normal",children:"B"})]})]}),(0,n.jsx)(e.annotation,{encoding:"application/x-tex",children:"\\dfrac{70  * 4 \\mathrm{bytes}}{32 / 4} * 1.2 = 42\\mathrm{GB}"})]})})}),(0,n.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,n.jsxs)(e.span,{className:"base",children:[(0,n.jsx)(e.span,{className:"strut",style:{height:"2.3074em",verticalAlign:"-0.936em"}}),(0,n.jsxs)(e.span,{className:"mord",children:[(0,n.jsx)(e.span,{className:"mopen nulldelimiter"}),(0,n.jsx)(e.span,{className:"mfrac",children:(0,n.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,n.jsxs)(e.span,{className:"vlist-r",children:[(0,n.jsxs)(e.span,{className:"vlist",style:{height:"1.3714em"},children:[(0,n.jsxs)(e.span,{style:{top:"-2.314em"},children:[(0,n.jsx)(e.span,{className:"pstrut",style:{height:"3em"}}),(0,n.jsx)(e.span,{className:"mord",children:(0,n.jsx)(e.span,{className:"mord",children:"32/4"})})]}),(0,n.jsxs)(e.span,{style:{top:"-3.23em"},children:[(0,n.jsx)(e.span,{className:"pstrut",style:{height:"3em"}}),(0,n.jsx)(e.span,{className:"frac-line",style:{borderBottomWidth:"0.04em"}})]}),(0,n.jsxs)(e.span,{style:{top:"-3.677em"},children:[(0,n.jsx)(e.span,{className:"pstrut",style:{height:"3em"}}),(0,n.jsxs)(e.span,{className:"mord",children:[(0,n.jsx)(e.span,{className:"mord",children:"70"}),(0,n.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,n.jsx)(e.span,{className:"mbin",children:"\u2217"}),(0,n.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,n.jsx)(e.span,{className:"mord",children:"4"}),(0,n.jsx)(e.span,{className:"mord",children:(0,n.jsx)(e.span,{className:"mord mathrm",children:"bytes"})})]})]})]}),(0,n.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,n.jsx)(e.span,{className:"vlist-r",children:(0,n.jsx)(e.span,{className:"vlist",style:{height:"0.936em"},children:(0,n.jsx)(e.span,{})})})]})}),(0,n.jsx)(e.span,{className:"mclose nulldelimiter"})]}),(0,n.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,n.jsx)(e.span,{className:"mbin",children:"\u2217"}),(0,n.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,n.jsxs)(e.span,{className:"base",children:[(0,n.jsx)(e.span,{className:"strut",style:{height:"0.6444em"}}),(0,n.jsx)(e.span,{className:"mord",children:"1.2"}),(0,n.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,n.jsx)(e.span,{className:"mrel",children:"="}),(0,n.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,n.jsxs)(e.span,{className:"base",children:[(0,n.jsx)(e.span,{className:"strut",style:{height:"0.6833em"}}),(0,n.jsx)(e.span,{className:"mord",children:"42"}),(0,n.jsx)(e.span,{className:"mord",children:(0,n.jsx)(e.span,{className:"mord mathrm",children:"GB"})})]})]})]})}),"\n",(0,n.jsx)(e.p,{children:"This is something you could run on 2 x L4 24GB GPUs."}),"\n",(0,n.jsx)(e.h3,{id:"relevant-tools-and-resources",children:"Relevant tools and resources"}),"\n",(0,n.jsxs)(e.ol,{children:["\n",(0,n.jsx)(e.li,{children:(0,n.jsx)(e.a,{href:"https://huggingface.co/spaces/Vokturz/can-it-run-llm",children:"Tool for checking how many GPUs you need for a specific model"})}),"\n",(0,n.jsx)(e.li,{children:(0,n.jsx)(e.a,{href:"https://blog.eleuther.ai/transformer-math/",children:"Transformer Math 101"})}),"\n"]}),"\n",(0,n.jsx)(e.p,{children:"Got more questions? Don't hesitate to join our Discord and ask away."}),"\n",(0,n.jsx)("a",{href:"https://discord.gg/JeXhcmjZVm",children:(0,n.jsx)("img",{alt:"discord-invite",src:"https://dcbadge.vercel.app/api/server/JeXhcmjZVm?style=flat"})})]})}function o(s={}){const{wrapper:e}={...(0,l.a)(),...s.components};return e?(0,n.jsx)(e,{...s,children:(0,n.jsx)(h,{...s})}):h(s)}},1151:(s,e,a)=>{a.d(e,{Z:()=>m,a:()=>t});var n=a(7294);const l={},r=n.createContext(l);function t(s){const e=n.useContext(r);return n.useMemo((function(){return"function"==typeof s?s(e):{...e,...s}}),[e,s])}function m(s){let e;return e=s.disableParentContext?"function"==typeof s.components?s.components(l):s.components||l:t(s.components),n.createElement(r.Provider,{value:e},s.children)}}}]);