{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81f96456-a74a-472f-8122-9d0c828f2b59",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_position: 2\n",
    "---\n",
    "\n",
    "# Serving Models\n",
    "\n",
    "<!-- THE MARKDOWN (.md) FILE IS GENERATED FROM THE NOTEBOOK (.ipynb) FILE -->\n",
    "\n",
    "The Substratus Server resource lets you serve models that were loaded into Substratus.\n",
    "Substratus provides a serving image that uses Basaran to provide an OpenAI\n",
    "compatible API endpoint and also a Web UI which is compatible with most of the\n",
    "Large Language Models on HuggingFace.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3c62ee",
   "metadata": {},
   "source": [
    "Create the Server resource by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc493d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl apply -f https://raw.githubusercontent.com/substratusai/substratus/main/examples/falcon-7b-instruct/server.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6a64be",
   "metadata": {},
   "source": [
    "The following Server resource is used:\n",
    "```yaml\n",
    "apiVersion: substratus.ai/v1\n",
    "kind: Server\n",
    "metadata:\n",
    "  name: falcon-7b-instruct\n",
    "spec:\n",
    "  image:\n",
    "    name: substratusai/model-server-basaran\n",
    "  model:\n",
    "    name: falcon-7b-instruct\n",
    "  resources:\n",
    "    gpu:\n",
    "      type: nvidia-l4\n",
    "      count: 1\n",
    "```\n",
    "In the Model resource spec the following things are configured:\n",
    "1. image.name: This is the image published by Substratus that can serve models.\n",
    "2. model.name: Refers to the name of the model that was loaded earlier in this tutorial\n",
    "3. resources: These specify what kind of resources are needed to serve the model. The Falcon-7b model requires GPUs to perform decently. In this case, 1 NVidia L4 GPU is requested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f63c87",
   "metadata": {},
   "source": [
    "It takes about 5 minutes to pull the container, load the model into GPU memory and being ready to serve requests. You can check if the Server is ready by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4e1d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl describe server falcon-7b-instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503c4307",
   "metadata": {},
   "source": [
    "By default Substratus creates a K8s Service to expose the Server, however this Service is of type ClusterIP, which means you can not directly access it over the internet. So let's use K8s Port Forwarding to access the server.\n",
    "\n",
    "Run the following command to forward your local 8080 port to the Server port 8080:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bec724",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl port-forward service/falcon-7b-instruct-server 8080:8080"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cac3822",
   "metadata": {},
   "source": [
    "You should now be able to access the web interface of the Server by going to\n",
    "[http://localhost:8080](http://localhost:8080)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
