{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "708b18ae-c2ed-4299-9ddd-8375428521fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "sidebar_position: 2\n",
    "---\n",
    "\n",
    "# Quickstart\n",
    "\n",
    "<!-- THE MARKDOWN (.md) FILE IS GENERATED FROM THE NOTEBOOK (.ipynb) FILE -->\n",
    "\n",
    "In this quickstart guide, you will install Substratus into a Google Cloud Platform project. Then you'll explore how Substratus can be used to load and deploy Open Source LLMs.\n",
    "\n",
    "NOTE: Support for AWS ([GitHub Issue #12](https://github.com/substratusai/substratus/issues/12)) and Azure ([GitHub Issue #63](https://github.com/substratusai/substratus/issues/63)) is planned. Give those issues a thumbs up if you would like to see them prioritized.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d69245f-c46c-4a2a-9ea3-8762eac462e8",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "You will need a [Google Cloud Platform](https://console.cloud.google.com/) project with billing enabled.\n",
    "\n",
    "Run the commands below to make sure you have the required tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06edd84-ac15-4be5-b8ab-676bbe4d025a",
   "metadata": {
    "tags": [
     "docker-version"
    ]
   },
   "outputs": [],
   "source": [
    "!docker version || open 'https://docs.docker.com/get-docker/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0931d4f-8dd3-4fef-a9ca-1350691d6b4b",
   "metadata": {
    "tags": [
     "gcloud-version"
    ]
   },
   "outputs": [],
   "source": [
    "!gcloud version || open 'https://cloud.google.com/sdk/docs/install'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866fb19c-db33-4367-b51a-bf6f902d541c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gke-gcloud-auth-plugin --version || gcloud components install gke-gcloud-auth-plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b6d646-9afe-43e2-abf9-22615b4fcd4e",
   "metadata": {
    "tags": [
     "kubectl-version"
    ]
   },
   "outputs": [],
   "source": [
    "!kubectl version --client || open 'https://kubernetes.io/docs/tasks/tools/#kubectl'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c58c96c7-b086-49ec-9963-e8ad6ff01d62",
   "metadata": {},
   "source": [
    "## Install Substratus in GCP\n",
    "\n",
    "Create a substratus GKE cluster along with supporting infrastructure (buckets, service accounts, image registries).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adb76f6-3f5a-47fb-b89b-b66dbfed6960",
   "metadata": {
    "tags": [
     "installer-gcp-up"
    ]
   },
   "outputs": [],
   "source": [
    "!docker run -it \\\n",
    "  -v ${HOME}/.kube:/root/.kube \\\n",
    "  -e PROJECT=$(gcloud config get project) \\\n",
    "  -e TOKEN=$(gcloud auth print-access-token) \\\n",
    "  substratusai/installer gcp-up.sh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54555fb1-8bdf-47b0-b97c-177b3db4ddad",
   "metadata": {},
   "source": [
    "`kubectl` should now be pointing at the substratus cluster.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e06320d8-daf9-4199-bf74-ac24129ebeda",
   "metadata": {},
   "source": [
    "## Deploy an Open Source Model\n",
    "\n",
    "To keep this quick, we'll use a smallish model, the falcon-7b-instruct model (just 7 billion parameters).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c63cdc-7d02-42b7-b2aa-69d2f0116877",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl apply -f https://raw.githubusercontent.com/substratusai/substratus/main/examples/falcon-7b-instruct/base-model.yaml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6288b3b-112b-4a2f-afad-cd1728263d3c",
   "metadata": {},
   "source": [
    "The model is now being downloaded from HuggingFace into a GCS bucket. This takes about 5 minutes.\n",
    "Let's also deploy the built model by applying a Server manifest. Server should start serving shortly after the Model build finishes (~3 minutes).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb39434c-caf2-4c63-b79f-74bc122a6f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl apply -f https://raw.githubusercontent.com/substratusai/substratus/main/examples/falcon-7b-instruct/server.yaml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f57db76a-ad3d-42c4-8612-dbab31b8d9c6",
   "metadata": {},
   "source": [
    "You can check on the progress of both processes using a single command.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dee9440-b029-419e-88a8-8c4c2b4d957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get ai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8408d23-92c6-435d-a510-a5e0bae0ed01",
   "metadata": {},
   "source": [
    "When the Server reports a `Ready` status, proceed to the next section to test it out.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "239ef216-9318-4679-83f0-98fcbed2a32c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing out the Server\n",
    "\n",
    "The way every company chooses to expose a model will be different. In most cases models are integrated into other business applications and are rarely exposed directly to the Internet. By default, substratus will only serve the model within the Kubernetes cluster (with a Kubernetes [Service](https://kubernetes.io/docs/concepts/services-networking/service/) object). From here, it's up to you to expose the model to a wider network (e.g., the internal VPC network or the Internet) via annotated Service or Ingress objects.\n",
    "\n",
    "In order to access the model for exploratory purposes, forward ports from within the cluster to your local machine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef93bee3-0c29-4435-a419-b7a21cf77ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl port-forward service/falcon-7b-instruct-server 8080:8080"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8bca86a6-8550-4884-a7fc-83b545ffe278",
   "metadata": {},
   "source": [
    "All substratus Servers ship with an API and interactive frontend. Open up your browser to [http://localhost:8080/](http://localhost:8080/) and talk to your model! Alternatively, request text generation via the OpenAI compatible HTTP API:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90825af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl http://localhost:8080/v1/completions \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{ \\\n",
    "    \"model\": \"falcon-7b-instruct\", \\\n",
    "    \"prompt\": \"Who was the first president of the United States? \", \\\n",
    "    \"max_tokens\": 10\\\n",
    "  }'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cdbd6c",
   "metadata": {},
   "source": [
    "```json\n",
    "{\n",
    "  \"id\": \"cmpl-e42772faf58cd46c18a955f1\",\n",
    "  \"object\": \"text_completion\",\n",
    "  \"created\": 1689485483,\n",
    "  \"model\": \"falcon-7b-instruct\",\n",
    "  \"choices\": [\n",
    "    {\n",
    "      \"text\": \"\\nGeorge Washington was the first president of the United States.\",\n",
    "      \"index\": 0,\n",
    "      \"logprobs\": null,\n",
    "      \"finish_reason\": \"length\"\n",
    "    }\n",
    "  ],\n",
    "  \"usage\": {\n",
    "    \"prompt_tokens\": 11,\n",
    "    \"completion_tokens\": 12,\n",
    "    \"total_tokens\": 23\n",
    "  }\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "95a9966d-5679-4208-9b28-0323aa80cd79",
   "metadata": {},
   "source": [
    "If you are interested in continuing your journey through Substratus, take a look at the [Guided Walkthrough](./category/walkthrough) to learn how to finetune models with your own dataset and much more!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cdb508e5-a7e9-4d94-a4d6-f3b4b2cf4e3f",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "The process that is serving the model can be stopped by simply deleting the same Server object that was applied before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d104d88e-5fa0-4cb6-87b0-869eb635ff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl delete -f https://raw.githubusercontent.com/substratusai/substratus/main/examples/falcon-7b-instruct/server.yaml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c6b78cea-8d41-4319-8769-2fa3ee0e02ff",
   "metadata": {},
   "source": [
    "If you want to uninstall the entire Substratus system and all infrastructure, you can run the `gcp-down.sh` script from the installation container.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6213000e-ad3e-4ed9-9a10-fd90c6e760fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -it \\\n",
    "  -e PROJECT=$(gcloud config get project) \\\n",
    "  -e TOKEN=$(gcloud auth print-access-token) \\\n",
    "  substratusai/installer gcp-down.sh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a21c7867-4e73-429c-a8d8-3c0792eb52b3",
   "metadata": {},
   "source": [
    "To learn more about how Substratus works, check out the [Architecture](./architecture) page.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
